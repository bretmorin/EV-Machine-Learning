{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA+4YH/GYwXKZOyUBt7gbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bretmorin/EV-Machine-Learning/blob/main/EV_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing Tools"
      ],
      "metadata": {
        "id": "4hYAwNyAdnPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ],
      "metadata": {
        "id": "awdCKr7mdtaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "otbbFXged5IW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the dataset"
      ],
      "metadata": {
        "id": "cPgdTJufdyGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset file\n",
        "dataset = pd.read_csv('NRELs Charging Data - Raw.csv')\n",
        "\n",
        "# Matrix of features, excluding the dependent variable column of 'expected_departure'\n",
        "X = dataset.drop('expected_departure', axis=1).values\n",
        "\n",
        "# Dependent variable column 'expected_departure' only\n",
        "y = dataset['expected_departure'].values"
      ],
      "metadata": {
        "id": "Q-bdpJm7eX7l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resolving missing data"
      ],
      "metadata": {
        "id": "T0-3XCPDd383"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find missing/Null data and resolve"
      ],
      "metadata": {
        "id": "uN-lnKP2ndm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change Null values in 'vehicle_model' to 'Other'; 7579 total\n",
        "dataset['vehicle_model'].fillna('Other', inplace=True)\n",
        "\n",
        "# To make sure X is updated with the new values\n",
        "X = dataset.drop('expected_departure', axis=1).values"
      ],
      "metadata": {
        "id": "fiJzfZpMeZCz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------Resolve Null values in 'start_date_time' and 'end_date_time'; 26,390 total, each------#\n",
        "\n",
        "# Convert columns to datetime objects; 'errors='coerce' to handle values that can't convert\n",
        "dataset['start_date_time'] = pd.to_datetime(dataset['start_date_time'], errors='coerce')\n",
        "dataset['end_date_time'] = pd.to_datetime(dataset['end_date_time'], errors='coerce')\n",
        "dataset['start_charge'] = pd.to_datetime(dataset['start_charge'], errors='coerce')\n",
        "dataset['termin_charge'] = pd.to_datetime(dataset['termin_charge'], errors='coerce')\n",
        "\n",
        "# Drop rows where both 'start_date_time' and 'end_date_time' are missing\n",
        "dataset = dataset.dropna(subset=['start_date_time', 'end_date_time'])\n",
        "\n",
        "# Reset the index after dropping rows\n",
        "dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Drop rows where both 'start_charge' and 'termin_charge' are missing\n",
        "dataset = dataset.dropna(subset=['start_charge', 'termin_charge'])\n",
        "\n",
        "# Reset the index after dropping rows\n",
        "dataset.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "srX43br9V9tt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resolve erroneous values in 'miles_requested'\n",
        "neg_miles = dataset[(dataset['miles_requested'] < 1)].index\n",
        "\n",
        "# Replace negative values with the mean of the remaining values in the column\n",
        "dataset.loc[neg_miles, 'miles_requested'] = dataset['miles_requested'].mean()\n",
        "\n",
        "# Sort by 'miles_requested' to verify it worked\n",
        "sorted_dataset = dataset.sort_values(by='miles_requested')"
      ],
      "metadata": {
        "id": "_sUjV9HwLDJV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resolve erroneous values in 'kwh_requested'\n",
        "neg_kwh = dataset[(dataset['kwh_requested'] < .01)].index\n",
        "\n",
        "# Replace negative values with the mean of the remaining values in the column\n",
        "dataset.loc[neg_kwh, 'kwh_requested'] = dataset['kwh_requested'].mean()\n",
        "\n",
        "# Sort by 'kwh_requested' to verify it worked\n",
        "sorted_dataset_2 = dataset.sort_values(by='kwh_requested')"
      ],
      "metadata": {
        "id": "o0PoZU4sQVX_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------Resolve Null values in 'max_charge_power' and 'energy_charged'; 486 total, each------#\n",
        "\n",
        "# Resolve erroneous values in 'energy_charged'\n",
        "zero_energy = dataset[dataset['energy_charged'] < 0.001].index\n",
        "\n",
        "# Add a small constant to all 'energy_charged' values to avoid being 0\n",
        "small_constant = 0.001\n",
        "dataset['energy_charged'] = dataset['energy_charged'].apply(lambda x: x + small_constant if x < 0.001 else x)\n",
        "\n",
        "# Replace negative values with the mean of the remaining values in the column\n",
        "dataset.loc[zero_energy, 'energy_charged'] = dataset['energy_charged'].mean()\n",
        "\n",
        "# Calculate the mean\n",
        "max_charge_power_mean = dataset['max_charge_power'].mean()\n",
        "energy_charged_mean = dataset['energy_charged'].mean()\n",
        "\n",
        "# Fill null values with the mean\n",
        "dataset['max_charge_power'].fillna(max_charge_power_mean, inplace=True)\n",
        "dataset['energy_charged'].fillna(energy_charged_mean, inplace=True)\n",
        "\n",
        "# Sort by 'energy_charged' to verify it worked\n",
        "sorted_dataset_3 = dataset.sort_values(by='max_charge_power')"
      ],
      "metadata": {
        "id": "UUTshj2iKhEf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop irrelevant columns\n",
        "dataset.drop(['driverId', 'station', 'controlled_duration', 'cost_for_session', 'afterPaid'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "IC0PEwl0Kxxl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creation of new columns to see differences in column data"
      ],
      "metadata": {
        "id": "-zNeCv2HM8Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#------Create column for comparing the request entry time vs the expected departure time------#\n",
        "\n",
        "# Convert 'expected_departure' and 'request_entry_time' columns to datetime\n",
        "dataset['expected_departure'] = pd.to_datetime(dataset['expected_departure'])\n",
        "dataset['request_entry_time'] = pd.to_datetime(dataset['request_entry_time'])\n",
        "\n",
        "# Create column for time difference(in seconds) between 'expected_departure' and 'request_entry_time'\n",
        "dataset['request_duration'] = (dataset['expected_departure'] - dataset['request_entry_time'])\n",
        "\n",
        "# Convert to timedelta\n",
        "dataset['request_duration'] = pd.to_timedelta(dataset['request_duration'], unit='s').round('1s')"
      ],
      "metadata": {
        "id": "cMMKTTVx1bAs"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------Create column for comparing the terminated charge time vs the start charge time------#\n",
        "\n",
        "# Convert 'start_charge' and 'termin_charge' columns to datetime\n",
        "dataset['termin_charge'] = pd.to_datetime(dataset['termin_charge'])\n",
        "dataset['start_charge'] = pd.to_datetime(dataset['start_charge'])\n",
        "\n",
        "# Create column for time difference(in seconds) between 'start_charge' and 'termin_charge'\n",
        "dataset['charge_duration'] = (dataset['termin_charge'] - dataset['start_charge']).dt.total_seconds()\n",
        "\n",
        "# Convert to timedelta\n",
        "dataset['charge_duration'] = pd.to_timedelta(dataset['charge_duration'], unit='s').round('1s')"
      ],
      "metadata": {
        "id": "EEQAhHHxIIsD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------Create column for comparing the charge time vs the expected duration------#\n",
        "\n",
        "# Convert 'expected_departure' and 'request_entry_time' columns to datetime\n",
        "dataset['expected_departure'] = pd.to_datetime(dataset['expected_departure'])\n",
        "dataset['request_entry_time'] = pd.to_datetime(dataset['request_entry_time'])\n",
        "\n",
        "# Create 'expected_duration', assuming 'expected_departure' and 'request_entry_time' are datetime columns\n",
        "dataset['expected_duration'] = (dataset['expected_departure'] - dataset['request_entry_time']).dt.total_seconds()\n",
        "\n",
        "# Convert 'charge_duration' to total seconds\n",
        "dataset['charge_duration_seconds'] = dataset['charge_duration'].dt.total_seconds()\n",
        "\n",
        "# Calculate the difference between 'charge_duration' and 'expected_duration'\n",
        "dataset['charge_vs_expected_diff'] = dataset['expected_duration'] - dataset['charge_duration_seconds']\n",
        "\n",
        "# Convert to timedelta\n",
        "dataset['charge_vs_expected_diff'] = pd.to_timedelta(dataset['charge_vs_expected_diff'], unit='s').round('1s')"
      ],
      "metadata": {
        "id": "d77ClAO1Uuo8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------Create column for calculating miles per hour based on requested miles vs actual charge duration------#\n",
        "\n",
        "# Set a minimum threshold for charge duration\n",
        "min_charge_duration_threshold = pd.Timedelta(minutes=5)\n",
        "\n",
        "# Calculate 'miles_per_hour'\n",
        "dataset['miles_per_hour'] = (dataset['miles_requested'] / (dataset['charge_duration'].dt.total_seconds() / 3600)).round(2)\n",
        "\n",
        "# Filter out cases with charge duration below the threshold\n",
        "dataset = dataset[dataset['charge_duration'] >= min_charge_duration_threshold]\n",
        "\n",
        "# Remove rows with infinite or NaN values in 'miles_per_hour'\n",
        "dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
        "dataset = dataset.dropna(subset=['miles_per_hour'])"
      ],
      "metadata": {
        "id": "CSZUZfV8U2Tj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[['request_duration', 'charge_duration']])\n",
        "print(dataset[['charge_vs_expected_diff', 'expected_duration', 'request_entry_time']])\n",
        "print(dataset['miles_per_hour'])"
      ],
      "metadata": {
        "id": "nagEUtrPiLIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding categorical data"
      ],
      "metadata": {
        "id": "g1n8jt3-d_bY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the Independent Variables"
      ],
      "metadata": {
        "id": "Hs1URltHeDnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "-yMpI6iPRT2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply one-hot encoding to the 'vehicle_model' column\n",
        "dataset = pd.get_dummies(dataset, columns=['vehicle_model'], prefix='vehicle')\n",
        "\n",
        "# Extract datetime features to capture time of day patterns\n",
        "dataset['day_of_week'] = dataset['request_entry_time'].dt.dayofweek\n",
        "dataset['hour_of_day'] = dataset['request_entry_time'].dt.hour"
      ],
      "metadata": {
        "id": "E89VtVCoR6MK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Winsorize 'miles_per_hour'\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Percentage limits for winsorization\n",
        "lower_limit = 0.0001  # 0.01%\n",
        "upper_limit = 0.0001   # 0.01%\n",
        "\n",
        "# Winsorize the 'miles_per_hour' column\n",
        "winsorized_miles_per_hour = winsorize(dataset['miles_per_hour'], limits=(lower_limit, upper_limit))\n",
        "\n",
        "# Replace the original 'miles_per_hour' column with the winsorized values\n",
        "dataset['miles_per_hour'] = winsorized_miles_per_hour"
      ],
      "metadata": {
        "id": "Dq5NABGsbGpH"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------This removes a small amount of outliers------#\n",
        "\n",
        "# Define a threshold to consider data points as outliers\n",
        "outlier_threshold = 400\n",
        "\n",
        "# Filter out rows with 'miles_per_hour' greater than the threshold\n",
        "dataset = dataset[dataset['miles_per_hour'] <= outlier_threshold]"
      ],
      "metadata": {
        "id": "YlzuOTe2thgc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding the Dependent Variable"
      ],
      "metadata": {
        "id": "6USA7DFqeHcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dependent variable is 'expected_duration', it doesn't need to be encoded as it is already in numerical form."
      ],
      "metadata": {
        "id": "_uxHKevUyP8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "I_IJu45Du4wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Number of Vehicles vs. Charging Duration\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(dataset['charge_duration'].dt.total_seconds() / 60, bins=30, kde=True)\n",
        "plt.title('Number of Vehicles vs. Charging Duration')\n",
        "plt.xlabel('Charging Duration (Minutes)')\n",
        "plt.ylabel('Number of Vehicles')\n",
        "plt.show()\n",
        "\n",
        "# Number of Vehicles vs. Energy Charged (kWh)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(dataset['energy_charged'], bins=20, kde=True)\n",
        "plt.title('Distribution of Energy Charged (kWh)')\n",
        "plt.xlabel('Energy Charged (kWh)')\n",
        "plt.ylabel('Number of Vehicles')\n",
        "plt.show()\n",
        "\n",
        "# Number of Vehicles vs. Day of the Week\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(dataset['day_of_week'], bins=7, kde=False)\n",
        "plt.title('Distribution of Charging by Day of Week')\n",
        "plt.xlabel('Day of Week')\n",
        "plt.ylabel('Number of Vehicles')\n",
        "plt.show()\n",
        "\n",
        "# Number of Vehicles vs. Start Hour of the Day\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x=dataset['start_date_time'].dt.hour)\n",
        "plt.title('Number of Vehicles vs. Start Hour of the Day')\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Number of Vehicles')\n",
        "plt.show()\n",
        "\n",
        "# Number of Vehicles vs. End Hour of the Day\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x=dataset['end_date_time'].dt.hour)\n",
        "plt.title('Number of Vehicles vs. End Hour of the Day')\n",
        "plt.xlabel('Hour of Day')\n",
        "plt.ylabel('Number of Vehicles')\n",
        "plt.show()\n",
        "\n",
        "# Energy Charged vs. kWh Requested\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(x='kwh_requested', y='energy_charged', data=dataset)\n",
        "plt.title('Energy Charged vs. kWh Requested')\n",
        "plt.xlabel('kWh Requested')\n",
        "plt.ylabel('Energy Charged')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3dv7-4Lgu5e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the dataset and training it with Random Forest Classification Model"
      ],
      "metadata": {
        "id": "JZiG8TMZeKOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert seconds to minutes\n",
        "dataset['charge_duration_minutes'] = dataset['charge_duration_seconds'] / 60\n",
        "\n",
        "# Define duration categories\n",
        "conditions = [\n",
        "    (dataset['charge_duration_minutes'] < 150),\n",
        "    (dataset['charge_duration_minutes'] >= 150) & (dataset['charge_duration_minutes'] <= 250),\n",
        "    (dataset['charge_duration_minutes'] > 250)\n",
        "]\n",
        "\n",
        "# Define category labels\n",
        "labels = ['short', 'medium', 'long']\n",
        "\n",
        "# Create new categorical column in the dataset\n",
        "dataset['duration_category'] = np.select(conditions, labels)"
      ],
      "metadata": {
        "id": "wX2qKXrVGbPo"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Selected model features\n",
        "features = dataset[['miles_requested', 'max_charge_power', 'kwh_requested', 'energy_charged', 'day_of_week', 'hour_of_day']]\n",
        "target = dataset['duration_category']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classification Model\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the Model\n",
        "predictions = rf_classifier.predict(X_test)\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNxH1zRZThto",
        "outputId": "b6a15e74-e7fb-43e7-be78-1a8b8502c7fa"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        long       0.78      0.73      0.75       672\n",
            "      medium       0.72      0.68      0.70       728\n",
            "       short       0.77      0.85      0.81       716\n",
            "\n",
            "    accuracy                           0.75      2116\n",
            "   macro avg       0.75      0.75      0.75      2116\n",
            "weighted avg       0.75      0.75      0.75      2116\n",
            "\n"
          ]
        }
      ]
    }
  ]
}